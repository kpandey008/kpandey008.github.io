<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Kushagra  Pandey


  | publications

</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/publications/">


<!-- Dark Mode -->
<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>



  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://kpandey008.github.io//">
       <span class="font-weight-bold">Kushagra</span>   Pandey
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/cv/">
                vitae
                
              </a>
          </li>
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description"></p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2023</h2>
  <ol class="bibliography">
<li><div class="row">
  <div class="col-sm-2 abbr">
    
    
    <abbr class="badge">NeurIPSâ€™23</abbr>
    
    
    
    
    <abbr class="badge Workshop">Workshop</abbr>
    
    
    
  </div>

  <div id="pandey2023towards" class="col-sm-8">
    
    <div class="title">Towards Fast Stochastic Sampling in Diffusion Generative Models</div>
    <div class="author">
      
      
      
      
      

      
      
      
      <em>Pandey, Kushagra</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Rudolph, Maja,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Mandt, Stephan
      
      
      
      
      
    </div>

    <div class="periodical">
      
      
      <em>NeurIPS 2023 Workshop on Diffusion Models</em>
      
      
      
      2023
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      <a href="https://openreview.net/forum?id=iSZZJjkjzu" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
      
      
      
      
      <a href="" class="btn btn-sm z-depth-0" role="button">Code</a>
      
      
      
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Diffusion models suffer from slow sample generation at inference time. Despite recent efforts, improving the sampling efficiency of stochastic samplers for diffusion models remains a promising direction. We propose Splitting Integrators for fast stochastic sampling in pre-trained diffusion models in augmented spaces. Commonly used in molecular dynamics, splitting-based integrators attempt to improve sampling efficiency by cleverly alternating between numerical updates involving the data, auxiliary, or noise variables. However, we show that a naive application of splitting integrators is sub-optimal for fast sampling. Consequently, we propose several modifications to improve sampling efficiency and denote the resulting samplers as Reduced Splitting Integrators. In the context of Phase Space Langevin Diffusion [Pandey &amp; Mandt, 2023] on CIFAR-10, our stochastic sampler achieves an FID score of 2.36 in only 100 network function evaluations (NFE) as compared to 2.63 for the best baselines.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-sm-2 abbr">
    
    
    <abbr class="badge">Arxiv</abbr>
    
    
    
    
  </div>

  <div id="Efficient" class="col-sm-8">
    
    <div class="title">Efficient Integrators for Diffusion Generative Models</div>
    <div class="author">
      
      
      
      
      

      
      
      
      <em>Pandey, Kushagra</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Rudolph, Maja,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Mandt, Stephan
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Under Submission<br>
      
      
      <em>Preprint. ArXiv</em>
      
      
      
      2023
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      <a href="https://arxiv.org/abs/2310.07894" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
      
      
      
      
      <a href="https://github.com/mandt-lab/PSLD" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
      
      
      
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Diffusion models suffer from slow sample generation at inference time. Therefore, developing a principled framework for fast deterministic/stochastic sampling for a broader class of diffusion models is a promising direction. We propose two complementary frameworks for accelerating sample generation in pretrained models: Conjugate Integrators and Splitting Integrators. Conjugate integrators generalize DDIM, mapping the reverse diffusion dynamics to a more
amenable space for sampling. In contrast, splitting-based integrators, commonly
used in molecular dynamics, reduce the numerical simulation error by cleverly
alternating between numerical updates involving the data and auxiliary variables. After extensively studying these methods empirically and theoretically,
we present a hybrid method that leads to the best-reported performance for diffusion models in augmented spaces. Applied to Phase Space Langevin Diffusion
[Pandey &amp; Mandt, 2023] on CIFAR-10, our deterministic and stochastic samplers achieve FID scores of 2.11 and 2.36 in only 100 network function evaluations (NFE) as compared to 2.57 and 2.63 for the best-performing baselines,
respectively. Our code and model checkpoints will be made publicly available at
https://github.com/mandt-lab/PSLD</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-sm-2 abbr">
    
    
    <abbr class="badge">ICCVâ€™23</abbr>
    
    
    
    
    <abbr class="badge Conference">Conference</abbr>
    
    
    
    
    <abbr class="badge Oral">Oral</abbr>
    
    
  </div>

  <div id="PSLD" class="col-sm-8">
    
    <div class="title">A Complete Recipe for Diffusion Generative Models</div>
    <div class="author">
      
      
      
      
      

      
      
      
      <em>Pandey, Kushagra</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      and Mandt, Stephan
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Oral Presentation (1.8% acceptance rate)<br>
      
      
      <em>International Conference on Computer Vision</em>
      
      
      
      2023
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Pandey_A_Complete_Recipe_for_Diffusion_Generative_Models_ICCV_2023_paper.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
      
      
      
      
      <a href="https://github.com/mandt-lab/PSLD" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
      
      
      
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Score-based Generative Models (SGMs) have demonstrated exceptional synthesis outcomes across various tasks. However, the current design landscape of the forward diffusion process remains largely untapped and often relies on physical heuristics or simplifying assumptions. Utilizing insights from the development of scalable Bayesian posterior samplers, we present a complete recipe for formulating forward processes in SGMs, ensuring convergence to the desired target distribution. Our approach reveals that several existing SGMs can be seen as specific manifestations of our framework. Building upon this method, we introduce Phase Space Langevin Diffusion (PSLD), which relies on score-based modeling within an augmented space enriched by auxiliary variables akin to physical phase space. Empirical results exhibit the superior sample quality and improved speed-quality trade-off of PSLD compared to various competing approaches on established image synthesis benchmarks. Remarkably, PSLD achieves sample quality akin to state-of-the-art SGMs (FID: 2.10 for unconditional CIFAR-10 generation). Lastly, we demonstrate the applicability of PSLD in conditional synthesis using pre-trained score networks, offering an appealing alternative as an SGM backbone for future advancements. Code and model checkpoints can be accessed at https://github.com/mandt-lab/PSLD</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
</ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography">
<li><div class="row">
  <div class="col-sm-2 abbr">
    
    
    <abbr class="badge">TMLR</abbr>
    
    
    
    
    <abbr class="badge Journal">Journal</abbr>
    
    
    
  </div>

  <div id="diffuseVAE" class="col-sm-8">
    
    <div class="title">DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from Low-Dimensional Latents</div>
    <div class="author">
      
      
      
      
      

      
      
      
      <em>Pandey, Kushagra</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Mukherjee, Avideep,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Rai, Piyush,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Kumar, Abhishek
      
      
      
      
      
    </div>

    <div class="periodical">
      
      
      <em>Transactions on Machine Learning Research</em>
      
      
      
      2022
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      <a href="https://arxiv.org/abs/2201.00308" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
      
      
      
      
      <a href="https://github.com/kpandey008/DiffuseVAE" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
      
      
      
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Diffusion Probabilistic models have been shown to generate state-of-the-art results on several competitive image synthesis benchmarks but lack a low-dimensional, interpretable latent space, and are slow at generation. On the other hand, Variational Autoencoders (VAEs) typically have access to a low-dimensional latent space but exhibit poor sample quality. Despite recent advances, VAEs usually require high-dimensional hierarchies of the latent codes to generate high-quality samples. We present DiffuseVAE, a novel generative framework that integrates VAE within a diffusion model framework, and leverage this to design a novel conditional parameterization for diffusion models. We show that the resulting model can improve upon the unconditional diffusion model in terms of sampling efficiency while also equipping diffusion models with the low-dimensional VAE inferred latent code. Furthermore, we show that the proposed model can generate high-resolution samples and exhibits synthesis quality comparable to state-of-the-art models on standard benchmarks. Lastly, we show that the proposed method can be used for controllable image synthesis and also exhibits out-of-the-box capabilities for downstream tasks like image super-resolution and denoising. For reproducibility, our source code is publicly available at this link.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
<li><div class="row">
  <div class="col-sm-2 abbr">
    
    
    <abbr class="badge">NAR</abbr>
    
    
    
    
    <abbr class="badge Journal">Journal</abbr>
    
    
    
  </div>

  <div id="10.1093/nar/gkac412" class="col-sm-8">
    
    <div class="title">Inference of cell state transitions and cell fate plasticity from single-cell with MARGARET</div>
    <div class="author">
      
      
      
      
      

      
      
      
      <em>Pandey, Kushagra</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      and Zafar, Hamim
      
      
      
      
      
    </div>

    <div class="periodical">
      
      
      <em>Nucleic Acids Research</em>
      
      
      May
      
      
      2022
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      <a href="https://watermark.silverchair.com/gkac412.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAs8wggLLBgkqhkiG9w0BBwagggK8MIICuAIBADCCArEGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMe5mdudRXKfBvtciBAgEQgIICgpazx7TJinKDjv-17zvV6IUQRV3AmrZU8NAgYlv3ju70WoVGR7Ig8Rj8i2UhFoUdK-NiQOzFESJTunyQFYNs7dp6GZ_FivvI0aA749dLjpdsjnCoRjgDQqFlESRMf8xMxC2kJhnPzo8MZpC20Rp-J-QwvtRTOwJl9h4mGiRnKWSy_9CGXboWHcVzttZDbbNDMC396nCQwtJTU2znlbsOqsWMJqY-KbjHH0KbMZ66rf5HRp7DtFRMernXclhdHekm1M6w31PX5AY6w2NsRbVhl7vDgfKfSprcx1mSz5tUH5HCn1Uve2HgZZRhM6H6jJORpbYQHrdnqRio8vEaf3zZ60eaUdA4zYD0IIpkat_eN90ie140dUWknP2BNaAOkuO_EcqNChdR3ZDKdOoBfoCSXT0URehC1sQyRzhfMBlyq-LgFnn75a_Y5DG9Q4R9lHoekMQTPmlMkVY5KCCFUCxlcAiUDNqwoOMxqc2BnWgbgyEbs-_gnNBszDtpTRIZDniAY4ncgU5_aHO5_Fgx6AVWh9bNQhIhy5yZMc0t3011CIwkIQs3R6x2gjBRu1zPEJHN8SIvA_N8cYmCrS73pc6SALoPQ0BDzspiaxFY6uRvqe6OmTgKyDXOID9VJ0QhAV_xJuGmi0niCwWS3Qm2N27KNX8wHprSrkxNNfw51-r6WXsZiEOMSYqFjX69WBPooiBIwLtR8Zpz1gHQLBUX8QlZwnRiHyxLcAqigS4_2_tkxP281x6X-qfo9tL-HJ4gxec0cebuJ7CS_pV1vgUsSsu_A3yJSC14O9zaaWaXz1SJNa1_KZVtCznnch1MHvl4QaQ4fs7S4xcmLSyCXFcsHfD5rDIHYw" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
      
      
      
      
      <a href="https://github.com/Zafar-Lab/Margaret" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
      
      
      
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Despite recent advances in inferring cellular dynamics using single-cell RNA-seq data, existing trajectory inference (TI) methods face difficulty in accurately reconstructing the cell-state manifold and cell-fate plasticity for complex topologies. Here, we present MARGARET (https://github.com/Zafar-Lab/Margaret) for inferring single-cell trajectory and fate mapping for diverse dynamic cellular processes. MARGARET reconstructs complex trajectory topologies using a deep unsupervised metric learning and a graph-partitioning approach based on a novel connectivity measure, automatically detects terminal cell states, and generalizes the quantification of fate plasticity for complex topologies. On a diverse benchmark consisting of synthetic and real datasets, MARGARET outperformed state-of-the-art methods in recovering global topology and cell pseudotime ordering. For human hematopoiesis, MARGARET accurately identified all major lineages and associated gene expression trends and helped identify transitional progenitors associated with key branching events. For embryoid body differentiation, MARGARET identified novel transitional populations that were validated by bulk sequencing and functionally characterized different precursor populations in the mesoderm lineage. For colon differentiation, MARGARET characterized the lineage for BEST4/OTOP2 cells and the heterogeneity in goblet cell lineage in the colon under normal and inflamed ulcerative colitis conditions. Finally, we demonstrated that MARGARET can scale to large scRNA-seq datasets consisting of âˆ¼ millions of cells.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li>
</ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
    
    
    <abbr class="badge">NeurIPSâ€™21</abbr>
    
    
    
    
    <abbr class="badge Workshop">Workshop</abbr>
    
    
    
    
    <abbr class="badge Oral">Oral</abbr>
    
    
  </div>

  <div id="vaedm" class="col-sm-8">
    
    <div class="title">VAEs meet Diffusion Models: Efficient and High-Fidelity Generation</div>
    <div class="author">
      
      
      
      
      

      
      
      
      <em>Pandey, Kushagra</em>,
      
      
      
      
      
      
      
      

      
      
      
      
      Mukherjee, Avideep,
      
      
      
      
      
      
      
      
      

      
      
      
      
      Rai, Piyush,
      
      
      
      
      
      
      
      
      

      
      
      
      
      and Kumar, Abhishek
      
      
      
      
      
    </div>

    <div class="periodical">
      
      Oral Presentation<br>
      
      
      <em>NeurIPSâ€™21, Workshop on Deep Generative Models and Downstream Applications</em>
      
      
      
      2021
      
    </div>
    

    <div class="links">
      
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      
      
      
      
      
      
      <a href="https://openreview.net/pdf?id=-J8dM4ed_92" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
      
      
      
      
      
      <a href="https://github.com/kpandey008/DiffuseVAE" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
      
      
      
      
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Diffusion Probabilistic models have been shown to generate state-of-the-art results on several competitive image synthesis benchmarks but lack a low-dimensional, interpretable latent space, and are slow at generation. On the other hand, Variational Autoencoders (VAEs) have access to a low-dimensional latent space but exhibit poor sample quality. Despite recent advances, VAEs usually require large dimensional hierarchies of the latent codes to generate high-quality samples. We present VAEDM, a novel generative framework for \textitrefining VAE generated samples using diffusion models while also presenting a novel conditional forward process parameterization for diffusion models. We show that the resulting parameterization can improve upon the unconditional diffusion model in terms of sampling efficiency during inference while also equipping diffusion models with the low-dimensional VAE inferred latent code.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div></li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    Â© Copyright 2024 Kushagra  Pandey.
    
    
    
  </div>
</footer>



  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>

  
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  





</html>
